{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is done here?\n",
    "We are using opensource repository imageai which will help us train YOLO-V3. This repository requires annotations to be done in PASCAL-VOC format. Also, for each image we need a corresponding annotation file. This notebook converts annotations into the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_file_path = '../data/trainval/annotations/bbox-annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annot_file_path) as f:\n",
    "    annot_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'annotations', 'categories', 'licenses'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'image_000000001.jpg',\n",
       " 'width': 1024,\n",
       " 'height': 768,\n",
       " 'id': 0,\n",
       " 'license': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dict['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category_id': 1,\n",
       " 'image_id': 0,\n",
       " 'segmentation': [],\n",
       " 'iscrowd': 0,\n",
       " 'bbox': [846, 145, 146, 477],\n",
       " 'area': 0.08855438232421875,\n",
       " 'id': 0,\n",
       " 'license': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dict['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'person', 'supercategory': 'none'},\n",
       " {'id': 2, 'name': 'car', 'supercategory': 'none'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dict['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://creativecommons.org/licenses/by/2.0/',\n",
       "  'id': 1,\n",
       "  'name': 'Attribution License'},\n",
       " {'url': 'https://creativecommons.org/licenses/by/4.0/',\n",
       "  'id': 2,\n",
       "  'name': 'Attribution License'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dict['licenses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearranging annotations to get annotations for every image at different file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ann_dic in enumerate(annot_dict['annotations']):\n",
    "    idd = ann_dic['image_id']\n",
    "    if 'objects' not in annot_dict['images'][idd]:\n",
    "        annot_dict['images'][idd]['objects'] = [ann_dic]\n",
    "    else:\n",
    "        annot_dict['images'][idd]['objects'].append(ann_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'image_000000001.jpg',\n",
       " 'width': 1024,\n",
       " 'height': 768,\n",
       " 'id': 0,\n",
       " 'license': 1,\n",
       " 'objects': [{'category_id': 1,\n",
       "   'image_id': 0,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [846, 145, 146, 477],\n",
       "   'area': 0.08855438232421875,\n",
       "   'id': 0,\n",
       "   'license': 2},\n",
       "  {'category_id': 1,\n",
       "   'image_id': 0,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [848, 216, 175, 551],\n",
       "   'area': 0.12261072794596355,\n",
       "   'id': 1,\n",
       "   'license': 2},\n",
       "  {'category_id': 2,\n",
       "   'image_id': 0,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [74, 159, 75, 81],\n",
       "   'area': 0.007724761962890625,\n",
       "   'id': 2,\n",
       "   'license': 2},\n",
       "  {'category_id': 2,\n",
       "   'image_id': 0,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [153, 124, 658, 643],\n",
       "   'area': 0.5379918416341146,\n",
       "   'id': 3,\n",
       "   'license': 2}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_dict['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeAnnotFile(annot_dict, save_path = '../data/trainval/annotations/'):\n",
    "    filename = annot_dict['file_name']\n",
    "    shape = [annot_dict['width'], annot_dict['height']]\n",
    "    \n",
    "    objs = ''''''\n",
    "    for obj in annot_dict['objects']:\n",
    "        label = 'person' if obj['category_id'] is 1 else 'car'\n",
    "        box = obj['bbox']\n",
    "        objs+=f'''\n",
    "    <object>\n",
    "        <name>{label}</name>\n",
    "        <pose>Unspecified</pose>\n",
    "        <truncated>0</truncated>\n",
    "        <difficult>0</difficult>\n",
    "        <bndbox>\n",
    "            <xmin>{int(box[0])}</xmin>\n",
    "            <ymin>{int(box[1])}</ymin>\n",
    "            <xmax>{int(box[0])+int(box[2])}</xmax>\n",
    "            <ymax>{int(box[1])+int(box[3])}</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "                '''\n",
    "\n",
    "    finalXML = f'''\n",
    "<annotation>\n",
    "    <folder>images</folder>\n",
    "    <filename>{filename}</filename>\n",
    "    <path>/home/dexter/Projects/interview/eagleView/data/trainval/images/{filename}</path>\n",
    "    <source>\n",
    "        <database>Unknown</database>\n",
    "    </source>\n",
    "    <size>\n",
    "        <width>{shape[1]}</width>\n",
    "        <height>{shape[0]}</height>\n",
    "        <depth>3</depth>\n",
    "    </size>\n",
    "    <segmented>0</segmented>\n",
    "{objs}\n",
    "</annotation>\n",
    "    '''\n",
    "    with open(save_path + filename[:-3] + 'xml','w') as f:\n",
    "        f.write(finalXML)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out XML annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2239/2239 [00:00<00:00, 5018.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for dic in tqdm(annot_dict['images']):\n",
    "    writeAnnotFile(dic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
